{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Of The Important Libraries Required for Solving This Problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import graphviz\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Untitled.ipynb',\n",
       " 'model.png',\n",
       " '.ipynb_checkpoints',\n",
       " 'negative.txt',\n",
       " 'Sentiment_Analysis_Udacity.ipynb',\n",
       " 'txt_sentoken',\n",
       " 'vocab.txt',\n",
       " 'review_polarity',\n",
       " 'positive.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step \n",
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load document into the notebook\n",
    "def load_document(fileName):\n",
    "    file=open(fileName,'r')\n",
    "    text_data=file.read()\n",
    "    file.close()\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning Step\n",
    "# Turn a document into tokens after processing it.\n",
    "\n",
    "def clean_document(document):\n",
    "    #split the review into tokens by white space\n",
    "    tokens=document.split()\n",
    "    # regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # removetokens which are not alphabetis\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # remove stop words\n",
    "    ##  A stop word is a commonly used word (such as “the”, “a”, “an”, “in”)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # remove out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['every', 'movie', 'comes', 'along', 'suspect', 'studio', 'every', 'indication', 'stinker', 'everybodys']\n"
     ]
    }
   ],
   "source": [
    "filename=\"txt_sentoken/pos/cv001_18431.txt\"\n",
    "text=load_document(filename)\n",
    "tokens=clean_document(text)\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save list to file\n",
    "def save_list(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc, clean and return line of tokens\n",
    "def doc_to_line(filename, vocab):\n",
    "    # load the doc\n",
    "    doc = load_doc(filename)\n",
    "    # clean doc\n",
    "    tokens = clean_doc(doc)\n",
    "    # filter by vocab\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory='txt_sentoken/neg'\n",
    "# for file in os.listdir(directory):\n",
    "#     if file.endswith(\".txt\"):\n",
    "#         doc=load_document(directory+'/'+file)\n",
    "#         print(\"Loaded Document %s\" % file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Load Document and then add the words to Vocab\n",
    "def document_to_vocabulary(fileName,vocab):\n",
    "    document=load_document(fileName)\n",
    "    tokens=clean_document(document)\n",
    "    vocab.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Process All the documents in the Directory\n",
    "def process_documents(directory, vocab):\n",
    "    count=0\n",
    "    for fileName in os.listdir(directory):\n",
    "        if fileName.endswith(\".txt\"):\n",
    "            path=directory+\"/\"+fileName\n",
    "            document_to_vocabulary(path,vocab)\n",
    "            count+=1\n",
    "    print(\"Total Number Of Files Processed In {d} = {n}\".format(d=directory,n=count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number Of Files Processed In txt_sentoken/neg = 1000\n",
      "Total Number Of Files Processed In txt_sentoken/pos = 1000\n"
     ]
    }
   ],
   "source": [
    "# Main Function To Process the documents \n",
    "# Global Varaible To Store The Count \n",
    "\n",
    "vocab = Counter()\n",
    "\n",
    "def develop_vocab():\n",
    "    global vocab\n",
    "#     vocab= Counter()\n",
    "    process_documents('txt_sentoken/neg', vocab)\n",
    "    process_documents('txt_sentoken/pos', vocab)\n",
    "    \n",
    "    \n",
    "    min_occur = 5\n",
    "    \n",
    "    tokens = [k for k,c in vocab.items() if c >= min_occur]\n",
    "    save_list(tokens,\"vocab.txt\")\n",
    "\n",
    "develop_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n"
     ]
    }
   ],
   "source": [
    "#Check Whether The File is Create or not \n",
    "if \"vocab.txt\" in os.listdir():\n",
    "    print(\"TRUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length Of The Vocabulary 46557\n"
     ]
    }
   ],
   "source": [
    "#print Length of the Vocabulary\n",
    "print(\"Total Length Of The Vocabulary %s\" %len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('film', 8860), ('one', 5521), ('movie', 5440), ('like', 3553), ('even', 2555), ('good', 2320), ('time', 2283), ('story', 2118), ('films', 2102), ('would', 2042), ('much', 2024), ('also', 1965), ('characters', 1947), ('get', 1921), ('character', 1906), ('two', 1825), ('first', 1768), ('see', 1730), ('well', 1694), ('way', 1668), ('make', 1590), ('really', 1563), ('little', 1491), ('life', 1472), ('plot', 1451), ('people', 1420), ('movies', 1416), ('could', 1395), ('bad', 1374), ('scene', 1373), ('never', 1364), ('best', 1301), ('new', 1277), ('many', 1268), ('doesnt', 1267), ('man', 1266), ('scenes', 1265), ('dont', 1210), ('know', 1207), ('hes', 1150), ('great', 1141), ('another', 1111), ('love', 1089), ('action', 1078), ('go', 1075), ('us', 1065), ('director', 1056), ('something', 1048), ('end', 1047), ('still', 1038)]\n"
     ]
    }
   ],
   "source": [
    "# 50 Most Common Words\n",
    "print(vocab.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Ten Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3a344d8128>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocabmcdf=pd.DataFrame(data=vocab.most_common(10),columns=['Word','Count'])\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.barplot(x='Word',y=\"Count\",data=vocabmcdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words in Vocab.txt is 14803\n"
     ]
    }
   ],
   "source": [
    "#Load The Vocabulary from Vocab.txt File.\n",
    "\n",
    "vocab_data=load_document(\"vocab.txt\")\n",
    "vocab_data=vocab_data.split()\n",
    "vocab=set(vocab_data)\n",
    "print(\"Number of Words in Vocab.txt is %s\" %len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Review For Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Negative.txt and Positive.txt from all the review documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review_documents(directory,vocab,train=False,op=0):\n",
    "    lines=[]\n",
    "    count=0\n",
    "    for file in os.listdir(directory):\n",
    "#         print(file)\n",
    "\n",
    "        if file.endswith(\".txt\"):\n",
    "            if not op:\n",
    "                if train and file.startswith(\"cv9\"):\n",
    "                    continue\n",
    "                if not train and not file.startswith(\"cv9\"):\n",
    "                    continue\n",
    "            count+=1\n",
    "            file_path=directory + '/' + file\n",
    "            lines_in_file=load_document(file_path)\n",
    "            tokens=clean_document(lines_in_file)\n",
    "            tokens=[w for w in tokens if w in vocab]\n",
    "            line=' '.join(tokens)\n",
    "        lines.append(line)\n",
    "#         print(lines)\n",
    "    print(\"Number of File Processed in {d} is {n}\".format(d=directory,n=count))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative lines from all the documents from \"txt_sentoken/neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of File Processed in txt_sentoken/neg is 1000\n",
      "Length of the Negative.txt File is 2124581 \n"
     ]
    }
   ],
   "source": [
    "# Negative lines from all the documents from \"txt_sentoken/neg\"\n",
    "neg_lines=process_review_documents(\"txt_sentoken/neg\",vocab_data,op=1)\n",
    "save_list(neg_lines,\"negative.txt\")\n",
    "\n",
    "#Load Negative Lines From negative.txt\n",
    "negative_lines=load_document(\"negative.txt\")\n",
    "print(\"Length of the Negative.txt File is %s \" %len(negative_lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studio attracted many weird bizarre people gates wonder film life death studio centers one boring cl\n"
     ]
    }
   ],
   "source": [
    "print(negative_lines[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive lines from all the documents from \"txt_sentoken/pos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of File Processed in txt_sentoken/pos is 1000\n",
      "Length of the Positive.txt File is 2408780 \n"
     ]
    }
   ],
   "source": [
    "# Negative lines from all the documents from \"txt_sentoken/neg\"\n",
    "pos_lines=process_review_documents(\"txt_sentoken/pos\",vocab_data,op=1)\n",
    "save_list(pos_lines,\"positive.txt\")\n",
    "\n",
    "#Load Negative Lines From negative.txr\n",
    "positive_lines=load_document(\"positive.txt\")\n",
    "print(\"Length of the Positive.txt File is %s \" %len(positive_lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "david lynchs blue velvet begins ends colorful bright shots flowers happy americans seemingly perfect\n"
     ]
    }
   ],
   "source": [
    "print(positive_lines[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_dataset(vocab,train=False):\n",
    "    neg=process_review_documents('txt_sentoken/neg', vocab,train)\n",
    "    pos=process_review_documents('txt_sentoken/pos', vocab,train)\n",
    "    docs=neg+pos\n",
    "    print(\"Length of   Negative Files = {n} \\t Positive Files= {p} \\t Doc = {d} \".format(n=len(neg),p=len(pos),d=len(docs)))\n",
    "    labels =[0 for i in range(len(neg))] + [1 for j in range(len(pos))]\n",
    "    return docs,labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "\n",
    "Dividing 90% 10% Ration 1000 Review Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of File Processed in txt_sentoken/neg is 900\n",
      "Number of File Processed in txt_sentoken/pos is 900\n",
      "Length of   Negative Files = 900 \t Positive Files= 900 \t Doc = 1800 \n"
     ]
    }
   ],
   "source": [
    "# load all training reviews\n",
    "train_docs, ytrain = load_clean_dataset(vocab,train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n"
     ]
    }
   ],
   "source": [
    "print(len(train_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n"
     ]
    }
   ],
   "source": [
    "print(len(ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of File Processed in txt_sentoken/neg is 100\n",
      "Number of File Processed in txt_sentoken/pos is 100\n",
      "Length of   Negative Files = 100 \t Positive Files= 100 \t Doc = 200 \n"
     ]
    }
   ],
   "source": [
    "test_docs, ytest = load_clean_dataset(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tokenizer To Implement Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function To Tokenize\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer=Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tokenizer\n",
    "tokenizer = create_tokenizer(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 14781) (200, 14781)\n"
     ]
    }
   ],
   "source": [
    "# encode data\n",
    "Xtrain = tokenizer.texts_to_matrix(train_docs, mode='freq')\n",
    "Xtest = tokenizer.texts_to_matrix(test_docs, mode='freq')\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14781"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words=Xtest.shape[1]\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(n_words):\n",
    "    # define network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ashish/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                739100    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 739,151\n",
      "Trainable params: 739,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ashish/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.6922 - acc: 0.5667\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.6851 - acc: 0.6983\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.6690 - acc: 0.7639\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.6429 - acc: 0.8917\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.6077 - acc: 0.9222\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.5669 - acc: 0.9278\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.5215 - acc: 0.9328\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.4773 - acc: 0.9383\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.4342 - acc: 0.9478\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.3942 - acc: 0.9522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a34314240>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit network\n",
    "model=define_model(n_words)\n",
    "model.fit(Xtrain, ytrain, epochs=10, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 160.00 191.00\" width=\"160pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-187 156,-187 156,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139887959516384 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139887959516384</title>\n",
       "<polygon fill=\"none\" points=\"12,-73.5 12,-109.5 140,-109.5 140,-73.5 12,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"76\" y=\"-87.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 139887959777352 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139887959777352</title>\n",
       "<polygon fill=\"none\" points=\"12,-.5 12,-36.5 140,-36.5 140,-.5 12,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"76\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 139887959516384&#45;&gt;139887959777352 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139887959516384-&gt;139887959777352</title>\n",
       "<path d=\"M76,-73.4551C76,-65.3828 76,-55.6764 76,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"79.5001,-46.5903 76,-36.5904 72.5001,-46.5904 79.5001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139887959782736 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139887959782736</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 152,-182.5 152,-146.5 0,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"76\" y=\"-160.8\">139887959782736</text>\n",
       "</g>\n",
       "<!-- 139887959782736&#45;&gt;139887959516384 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139887959782736-&gt;139887959516384</title>\n",
       "<path d=\"M76,-146.4551C76,-138.3828 76,-128.6764 76,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"79.5001,-119.5903 76,-109.5904 72.5001,-119.5904 79.5001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot of The Defined model\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 48.480350\n",
      "Test Accuracy: 88.000000\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, acc  = model.evaluate(Xtest, ytest, verbose=0)\n",
    "print('Test Loss: %f' % (loss*100))\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Sentiment For Reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review, vocab, tokenizer, model):\n",
    "    tokens = clean_document(review)\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    # encode\n",
    "    encoded = tokenizer.texts_to_matrix([line], mode='freq')\n",
    "    # predict sentiment\n",
    "    yhat = model.predict(encoded, verbose=0)\n",
    "    percent_pos = yhat[0,0]\n",
    "    if round(percent_pos) == 0:\n",
    "        return (1-percent_pos), 'NEGATIVE'\n",
    "    return percent_pos, 'POSITIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: [Best movie ever! It was great, I recommend it.]\n",
      "Sentiment: POSITIVE \n",
      "Review: [This is a bad movie.]\n",
      "Sentiment: NEGATIVE \n",
      "Review: [An above average one for one time watch.]\n",
      "Sentiment: POSITIVE \n",
      "Review: [Very heart touching and making us proud movie. The acting done by akshay Kumar is awesome in the movie.   The whole theater was emotional at the end of the movie.]\n",
      "Sentiment: NEGATIVE \n",
      "Review: [one Of the Best Movie evar made in Bollywood on War What a wonderful Location and Sets Akshay Kumar Naild it Again and proven again that why He is king Of the Bollywood]\n",
      "Sentiment: POSITIVE \n"
     ]
    }
   ],
   "source": [
    "text = 'Best movie ever! It was great, I recommend it.'\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print('Review: [%s]\\nSentiment: %s ' % (text, sentiment))\n",
    "# test negative text\n",
    "\n",
    "text = 'This is a bad movie.'\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print('Review: [%s]\\nSentiment: %s ' % (text, sentiment))\n",
    "\n",
    "text = 'An above average one for one time watch.'\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print('Review: [%s]\\nSentiment: %s ' % (text, sentiment))\n",
    "\n",
    "\n",
    "text = \"Very heart touching and making us proud movie. The acting done \\\n",
    "by akshay Kumar is awesome in the movie.   \\\n",
    "The whole theater was emotional at the end of the movie.\"\n",
    "\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print('Review: [%s]\\nSentiment: %s ' % (text, sentiment))\n",
    "\n",
    "text = \"one Of the Best Movie evar made in Bollywood on War What a wonderful \\\n",
    "Location and Sets Akshay Kumar Naild it Again and proven again that why He is king Of the Bollywood\"\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print('Review: [%s]\\nSentiment: %s ' % (text, sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Word Scoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4694 - acc: 0.7794\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 875us/step - loss: 0.0562 - acc: 0.9956\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 870us/step - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 880us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 859us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 871us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 877us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 880us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 881us/step - loss: 9.4794e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 864us/step - loss: 7.4124e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 327us/step\n",
      "1 accuracy : 0.92 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 982us/step - loss: 0.4564 - acc: 0.8000\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 840us/step - loss: 0.0506 - acc: 0.9944\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 846us/step - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 846us/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 844us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 839us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 843us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 854us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 846us/step - loss: 9.0999e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 847us/step - loss: 6.8638e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 363us/step\n",
      "2 accuracy : 0.92 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4644 - acc: 0.7878\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 857us/step - loss: 0.0549 - acc: 0.9961\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 859us/step - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 844us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 846us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 844us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 857us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 850us/step - loss: 9.7208e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 852us/step - loss: 6.6718e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 847us/step - loss: 4.8422e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 408us/step\n",
      "3 accuracy : 0.93 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 986us/step - loss: 0.4991 - acc: 0.7500\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 841us/step - loss: 0.0716 - acc: 0.9911\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 848us/step - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 848us/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 846us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 844us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 854us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 845us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 845us/step - loss: 9.2120e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 851us/step - loss: 7.1805e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 451us/step\n",
      "4 accuracy : 0.93 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4929 - acc: 0.7661\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 875us/step - loss: 0.0813 - acc: 0.9878\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 879us/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 857us/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 837us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 882us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 9.9230e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 7.3557e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 866us/step - loss: 5.6794e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 498us/step\n",
      "5 accuracy : 0.91 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5194 - acc: 0.7539\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0975 - acc: 0.9844\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 8.1166e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 5.7275e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 4.1155e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 699us/step\n",
      "6 accuracy : 0.905 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4701 - acc: 0.7761A: 1s - loss: 0.560\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0533 - acc: 0.9956\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 6.4836e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 4.5425e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 734us/step\n",
      "7 accuracy : 0.925 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4840 - acc: 0.7650\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0645 - acc: 0.9917\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 993us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 8.9930e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 747us/step\n",
      "8 accuracy : 0.915 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4561 - acc: 0.7883\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0459 - acc: 0.9939A: 0s - loss: 0.04\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 9.5962e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "9 accuracy : 0.925 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4692 - acc: 0.7678\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0605 - acc: 0.9917\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0150 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 998us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 999us/step - loss: 7.2996e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 866us/step\n",
      "10 accuracy : 0.92 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4692 - acc: 0.7744\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0631 - acc: 0.9917\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 7.9400e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "1 accuracy : 0.895 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4566 - acc: 0.7867\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0521 - acc: 0.9922\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 994us/step - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 994us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 983us/step\n",
      "2 accuracy : 0.905 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4794 - acc: 0.7511\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0621 - acc: 0.9894\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 8.7859e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "3 accuracy : 0.895 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4556 - acc: 0.7883\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0516 - acc: 0.9894\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 9.8160e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "4 accuracy : 0.895 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4658 - acc: 0.7767\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0528 - acc: 0.9933\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 8.5190e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 6.5286e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "5 accuracy : 0.885 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.4529 - acc: 0.7839\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0442 - acc: 0.9933\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 989us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 898us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 974us/step - loss: 9.8110e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "6 accuracy : 0.875 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.4613 - acc: 0.7922\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 979us/step - loss: 0.0489 - acc: 0.9961\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 978us/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 905us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 922us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 945us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 955us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 991us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 984us/step - loss: 8.9001e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 845us/step - loss: 6.9437e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "7 accuracy : 0.875 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4477 - acc: 0.7889\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0453 - acc: 0.9939\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 907us/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 7.8944e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 6.0248e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "8 accuracy : 0.895 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4652 - acc: 0.7761\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0611 - acc: 0.9906\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 925us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 983us/step - loss: 7.4651e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 5.6038e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "9 accuracy : 0.895 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4504 - acc: 0.7994\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 874us/step - loss: 0.0481 - acc: 0.9928\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 994us/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 978us/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 887us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 902us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 917us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 883us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 884us/step - loss: 8.0616e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 903us/step - loss: 6.1272e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "10 accuracy : 0.885 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4781 - acc: 0.7422\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 921us/step - loss: 0.0208 - acc: 0.9978\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 968us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 964us/step - loss: 7.7558e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 880us/step - loss: 5.5467e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 902us/step - loss: 4.2230e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 3.2463e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 2.5872e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "1 accuracy : 0.845 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4653 - acc: 0.7778\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 996us/step - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 7.4119e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 5.2927e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 3.9095e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 3.0290e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 2.4159e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "2 accuracy : 0.865 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.4928 - acc: 0.7544\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0231 - acc: 0.9972\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0044 - acc: 0.9994\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 8.1980e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 5.7484e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 3.9825e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 3.0215e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 2.3403e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "3 accuracy : 0.845 \n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.4690 - acc: 0.7722\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0184 - acc: 0.9994\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 6.9740e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 5.0353e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 3.8501e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 2.9850e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 2.3823e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "4 accuracy : 0.88 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4797 - acc: 0.7706\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0205 - acc: 0.9983\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 8.4284e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 5.9228e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 4.4319e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 3.4125e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 2.7091e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "5 accuracy : 0.875 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4515 - acc: 0.7828\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0164 - acc: 0.9983\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0011 - acc: 1.0000- ETA: 1s - los\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 7.5554e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 5.3998e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 4.0511e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 3.0960e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 2.4596e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "6 accuracy : 0.88 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4666 - acc: 0.7806\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0141 - acc: 0.9989\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 7.3946e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 5.4132e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 4.1392e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 3.2235e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 2.5321e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 0s 2ms/step\n",
      "7 accuracy : 0.88 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4622 - acc: 0.7811\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.0123 - acc: 0.9983\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 7.5965e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 5.4859e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 4.1196e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 3.1986e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 2.5271e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "8 accuracy : 0.86 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.4649 - acc: 0.7722\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0164 - acc: 0.9983\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 8.1252e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 5.7922e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 4.3057e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 3.3390e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 2.6509e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "9 accuracy : 0.875 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 5s 3ms/step - loss: 0.4586 - acc: 0.7817\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0158 - acc: 0.9989\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 8.3211e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 5.7326e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 4.0830e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 3.0182e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 2.2786e-04 - acc: 1.0000\n",
      "200/200 [==============================] - 1s 4ms/step\n",
      "10 accuracy : 0.87 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.6920 - acc: 0.4972\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6846 - acc: 0.5072\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6714 - acc: 0.6861\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6505 - acc: 0.7650\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.6226 - acc: 0.8761\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.5893 - acc: 0.8833\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.5522 - acc: 0.9356\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.5129 - acc: 0.9567\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.4743 - acc: 0.9611\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4359 - acc: 0.9661\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "1 accuracy : 0.88 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 5s 3ms/step - loss: 0.6917 - acc: 0.5528\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6821 - acc: 0.7311\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.6631 - acc: 0.8072\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6342 - acc: 0.9017A: 0s - loss: 0.6\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.5974 - acc: 0.9161\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.5540 - acc: 0.9489\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5084 - acc: 0.9467\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4617 - acc: 0.9578\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4183 - acc: 0.9633\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.3759 - acc: 0.9711\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "2 accuracy : 0.87 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.6913 - acc: 0.5211\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.6802 - acc: 0.8767\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6592 - acc: 0.9067\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6291 - acc: 0.8606\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5862 - acc: 0.9372\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5398 - acc: 0.9439\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4906 - acc: 0.9489\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4425 - acc: 0.9522\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.3967 - acc: 0.9633\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.3572 - acc: 0.9650\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "3 accuracy : 0.865 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.6910 - acc: 0.6061\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6789 - acc: 0.7694\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.6578 - acc: 0.8956\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6266 - acc: 0.9183\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5876 - acc: 0.9300\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5438 - acc: 0.9306\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4959 - acc: 0.9533\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4511 - acc: 0.9533\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4070 - acc: 0.9594\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.3661 - acc: 0.9672\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "4 accuracy : 0.865 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.6914 - acc: 0.6589\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6806 - acc: 0.8678\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.6621 - acc: 0.9089\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6336 - acc: 0.9294\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5974 - acc: 0.9383\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5563 - acc: 0.9417\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5125 - acc: 0.9506\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4683 - acc: 0.9533\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4258 - acc: 0.9583\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.3867 - acc: 0.9611\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "5 accuracy : 0.87 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.6915 - acc: 0.5633\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.6826 - acc: 0.6106\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6666 - acc: 0.8039\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6423 - acc: 0.8222\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6103 - acc: 0.9306\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.5727 - acc: 0.9339\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.5316 - acc: 0.9494\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4900 - acc: 0.9494\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4485 - acc: 0.9583\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4088 - acc: 0.9644\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "6 accuracy : 0.855 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.6915 - acc: 0.6172\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6813 - acc: 0.8506\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6601 - acc: 0.8922\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6260 - acc: 0.8978\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.5825 - acc: 0.9344\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.5334 - acc: 0.9428\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.4831 - acc: 0.9522\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4327 - acc: 0.9567\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.3852 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.3443 - acc: 0.9700\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "7 accuracy : 0.865 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 5s 3ms/step - loss: 0.6915 - acc: 0.5844\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6811 - acc: 0.6522\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.6623 - acc: 0.8700\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6343 - acc: 0.8528\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.5980 - acc: 0.9328\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.5566 - acc: 0.9372\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.5120 - acc: 0.9494\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4669 - acc: 0.9561\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.4238 - acc: 0.9628\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.3824 - acc: 0.9667\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "8 accuracy : 0.86 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.6910 - acc: 0.5022\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6790 - acc: 0.5661\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6596 - acc: 0.7111\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6322 - acc: 0.7872\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.5994 - acc: 0.8461\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5609 - acc: 0.8956\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5199 - acc: 0.9417\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4782 - acc: 0.9567\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.4359 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.3957 - acc: 0.9744\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "9 accuracy : 0.855 \n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.6925 - acc: 0.4978\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.6872 - acc: 0.6311\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.6757 - acc: 0.6578\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6560 - acc: 0.8261\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.6292 - acc: 0.8828\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.5970 - acc: 0.9294\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.5605 - acc: 0.9417\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.5225 - acc: 0.9489\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.4834 - acc: 0.9556\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 3s 1ms/step - loss: 0.4448 - acc: 0.9617\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "10 accuracy : 0.865 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "modes= ['binary', 'count', 'tfidf', 'freq']\n",
    "#Prepare Bag - Of - Words Encoding\n",
    "results=pd.DataFrame()\n",
    "def prepare_data(train,test,m):\n",
    "    token=Tokenizer()\n",
    "    token.fit_on_texts(train)\n",
    "    Xtrain=token.texts_to_matrix(train, mode=mode)\n",
    "    Xtest = token.texts_to_matrix(test, mode=mode)\n",
    "    return Xtrain,Xtest\n",
    "\n",
    "#Evaluate\n",
    "def evaluate_mode(Xtrain,ytrain,Xtest,ytest):\n",
    "    scores=list()\n",
    "    no_r=10\n",
    "    for _ in range(no_r):\n",
    "        model=Sequential() \n",
    "        model.add(Dense(50,input_shape=(n_words,),activation='relu'))\n",
    "        model.add(Dense(1,activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        model.fit(Xtrain,ytrain,epochs=10,verbose=1)\n",
    "        loss,acc=model.evaluate(Xtest,ytest,verbose=1)\n",
    "        scores.append(acc)\n",
    "        print(\"%d accuracy : %s \"%((_+1),acc))\n",
    "    return scores\n",
    "\n",
    "for mode in modes:\n",
    "    Xtrain, Xtest = prepare_data(train_docs, test_docs, mode)\n",
    "    results[mode] = evaluate_mode(Xtrain, ytrain, Xtest, ytest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          binary      count      tfidf       freq\n",
      "count  10.000000  10.000000  10.000000  10.000000\n",
      "mean    0.920000   0.890000   0.867500   0.865000\n",
      "std     0.008165   0.009718   0.013591   0.007454\n",
      "min     0.905000   0.875000   0.845000   0.855000\n",
      "25%     0.916250   0.885000   0.861250   0.861250\n",
      "50%     0.920000   0.895000   0.872500   0.865000\n",
      "75%     0.925000   0.895000   0.878750   0.868750\n",
      "max     0.930000   0.905000   0.880000   0.880000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results.describe())\n",
    "plt.figure(figsize=(16,6))\n",
    "results.boxplot()\n",
    "plt.xlabel(\"Types\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
